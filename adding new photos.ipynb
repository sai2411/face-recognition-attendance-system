{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9768197",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-8.4.0-cp36-cp36m-win_amd64.whl (3.2 MB)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-win_amd64.whl (423.3 MB)\n",
      "Collecting mtcnn\n",
      "  Using cached mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-win_amd64.whl (8.7 MB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp36-cp36m-win_amd64.whl (897 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\saina\\anaconda3\\envs\\att\\lib\\site-packages (from tensorflow) (0.37.1)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.46.3-cp36-cp36m-win_amd64.whl (3.5 MB)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-win_amd64.whl (2.7 MB)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\saina\\anaconda3\\envs\\att\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2017.2\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\saina\\anaconda3\\envs\\att\\lib\\site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.0.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\saina\\anaconda3\\envs\\att\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting dataclasses\n",
      "  Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Building wheels for collected packages: sklearn, clang, termcolor, wrapt\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=18f7557548dae1c90a368c71ad476fe4cff3849d597d4a933190f94fa0bd8763\n",
      "  Stored in directory: c:\\users\\saina\\appdata\\local\\pip\\cache\\wheels\\23\\9d\\42\\5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "  Building wheel for clang (setup.py): started\n",
      "  Building wheel for clang (setup.py): finished with status 'done'\n",
      "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30694 sha256=17758bba73edcb4ea2e37c2301b79beacc669eace8a595a5250384110af66994\n",
      "  Stored in directory: c:\\users\\saina\\appdata\\local\\pip\\cache\\wheels\\22\\4c\\94\\0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=7955b3ca184b4c456014c137d869455674aab35531bc990cf31b5d02e27e3cdb\n",
      "  Stored in directory: c:\\users\\saina\\appdata\\local\\pip\\cache\\wheels\\93\\2a\\eb\\e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-win_amd64.whl size=33494 sha256=95a492401931f02986b8c04387a2dca24505ca6513cb5ee4b5ed07eb8cf61c31\n",
      "  Stored in directory: c:\\users\\saina\\appdata\\local\\pip\\cache\\wheels\\32\\42\\7f\\23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "Successfully built sklearn clang termcolor wrapt\n",
      "Installing collected packages: urllib3, pyasn1, idna, charset-normalizer, zipp, typing-extensions, six, rsa, requests, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, numpy, importlib-metadata, google-auth, dataclasses, werkzeug, threadpoolctl, tensorboard-plugin-wit, tensorboard-data-server, scipy, protobuf, markdown, joblib, grpcio, google-auth-oauthlib, cached-property, absl-py, wrapt, termcolor, tensorflow-estimator, tensorboard, scikit-learn, pytz, opt-einsum, opencv-python, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, clang, astunparse, tensorflow, sklearn, pillow, pandas, mtcnn\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cached-property-1.5.2 cachetools-4.2.4 charset-normalizer-2.0.12 clang-5.0 dataclasses-0.8 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.3 h5py-3.1.0 idna-3.3 importlib-metadata-4.8.3 joblib-1.1.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.7 mtcnn-0.1.1 numpy-1.19.5 oauthlib-3.2.0 opencv-python-4.6.0.66 opt-einsum-3.3.0 pandas-1.1.5 pillow-8.4.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytz-2022.1 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 scikit-learn-0.24.2 scipy-1.5.4 six-1.15.0 sklearn-0.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 threadpoolctl-3.1.0 typing-extensions-3.7.4.3 urllib3-1.26.9 werkzeug-2.0.3 wrapt-1.12.1 zipp-3.6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install opencv-python numpy pillow sklearn tensorflow mtcnn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188b5355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import Normalizer, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bde9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your name --> leela prasad sir\n",
      "Enter your roll no --> 555\n",
      "\n",
      "Capturing starts in 5 seconds...\n",
      "Capturing starts in 4 seconds...\n",
      "Capturing starts in 3 seconds...\n",
      "Capturing starts in 2 seconds...\n",
      "Capturing starts in 1 seconds...\n",
      "Taking photos...\n",
      "Successfully taken your photos...\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Embedding Model Loaded\n",
      "Loading train data...\n",
      "Loaded 30 images of brock-1234\n",
      "Loaded 30 images of leela prasad sir-555\n",
      "\n",
      "Loading test data...\n",
      "Loaded 10 images of brock-1234\n",
      "Loaded 10 images of leela prasad sir-555\n",
      "\n",
      "SVM Model saved successfully!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:os.makedirs('faces')\n",
    "except:pass\n",
    "\n",
    "try:os.makedirs('faces/train')\n",
    "except:pass\n",
    "\n",
    "try:os.makedirs('faces/val')\n",
    "except:pass\n",
    "\n",
    "\n",
    "\n",
    "name = input('Enter your name --> ')\n",
    "roll = input('Enter your roll no --> ')\n",
    "\n",
    "name = name+'-'+roll\n",
    "\n",
    "\n",
    "\n",
    "if name in os.listdir('faces/train'):\n",
    "    print('User already exist in faces')\n",
    "\n",
    "else:    \n",
    "    os.makedirs('faces/train/'+name)\n",
    "    os.makedirs('faces/val/'+name)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    i = 0\n",
    "    print()\n",
    "    for i in range(5):\n",
    "        print(f'Capturing starts in {5-i} seconds...')\n",
    "        time.sleep(1)\n",
    "    print('Taking photos...')\n",
    "    while i<=200:\n",
    "        ret,frame = cap.read()\n",
    "        cv2.imshow('taking your pictures',frame)\n",
    "        if i%5==0 and i<=150 and i!=0:\n",
    "            cv2.imwrite('faces/train/'+name+'/'+str(i)+'.png',frame)\n",
    "        elif i%5==0 and i>150:\n",
    "            cv2.imwrite('faces/val/'+name+'/'+str(i)+'.png',frame)\n",
    "        i+=1\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    print('Successfully taken your photos...')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embedding_model = load_model('models/facenet_keras.h5')\n",
    "print('Embedding Model Loaded')\n",
    "\n",
    "\n",
    "detector = MTCNN()\n",
    "\n",
    "def find_face(path,img_size=(160,160)):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = np.asarray(img) # converting our image obj to numpy array\n",
    "    faces = detector.detect_faces(img)\n",
    "    if faces:\n",
    "        x,y,w,h = faces[0]['box']\n",
    "        x,y=abs(x),abs(y)\n",
    "        face = img[y:y+h,x:x+w]\n",
    "        face = Image.fromarray(face) # converting it to image object to resize it\n",
    "        face = face.resize(img_size) # resizing it\n",
    "        face = np.asarray(face)      # converting it back to array\n",
    "        return face\n",
    "    return None\n",
    "\n",
    "\n",
    "def embed(face):\n",
    "    face = face.astype('float32')\n",
    "    fm,fs = face.mean(),face.std()\n",
    "    face = (face-fm)/fs # standardizing the data \n",
    "    face = np.expand_dims(face,axis=0) # flattening it\n",
    "    embs = embedding_model.predict(face) # embedding model converts our160*160*3 vector to 128 features\n",
    "    return embs[0]\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    X = []\n",
    "    y = []\n",
    "    for people in os.listdir(path):\n",
    "        for people_images in os.listdir(path+people):\n",
    "            face = find_face(path+people+'/'+people_images)\n",
    "            if face is None:continue\n",
    "            emb = embed(face)\n",
    "            X.append(emb)\n",
    "            y.append(people)\n",
    "        print('Loaded {} images of {}'.format(len(os.listdir(path+'/'+people)),people)) \n",
    "    return np.asarray(X),np.asarray(y)\n",
    "\n",
    "\n",
    "print('Loading train data...')\n",
    "X_train, y_train = load_dataset('faces/train/')\n",
    "\n",
    "print()\n",
    "\n",
    "print('Loading test data...')\n",
    "X_test, y_test = load_dataset('faces/val/')\n",
    "\n",
    "\n",
    "l2_normalizer = Normalizer('l2')\n",
    "\n",
    "X_train = l2_normalizer.transform(X_train)\n",
    "X_test  = l2_normalizer.transform(X_test)\n",
    "\n",
    "\n",
    "label_enc = LabelEncoder()\n",
    "y_train = label_enc.fit_transform(y_train)\n",
    "y_test = label_enc.transform(y_test)\n",
    "\n",
    "\n",
    "svc = SVC(kernel='linear',probability=True)\n",
    "svc.fit(X_train,y_train)\n",
    "joblib.dump(svc,'models/face_prediction_model.sav')\n",
    "print()\n",
    "\n",
    "print('SVM Model saved successfully!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ab57642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
